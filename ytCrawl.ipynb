{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ytCrawl.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XzMKdpxu-mn",
        "outputId": "b8efd882-f2a4-4102-b1fb-09221c33ecda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install isodate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: isodate in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from isodate) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihtSvBkgvFuQ",
        "outputId": "90479293-67c4-42b7-c9f3-2882d38a6e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install Sastrawi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwg6dRT_xHNS",
        "outputId": "aa0c1aa5-3fa5-4c11-875c-9fc8a4fb9758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PViDmyMPuxho",
        "outputId": "5cb7469f-0063-418e-ce6e-0804304dc4c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from apiclient.discovery import build\n",
        "import googleapiclient.discovery\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from dateutil import parser\n",
        "import numpy as np\n",
        "from nltk.probability import FreqDist\n",
        "import re, nltk\n",
        "import nltk\n",
        "import string\n",
        "import isodate\n",
        "from nltk import word_tokenize\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "factory = StopWordRemoverFactory()\n",
        "stopwords = factory.get_stop_words()\n",
        "\n",
        "os.environ[\"TZ\"]=\"Asia/Jakarta\"\n",
        "time.tzset()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocessing(line):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        \tu\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        \tu\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        \tu\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        \tu\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    line=emoji_pattern.sub(r'', line) # no emoji\n",
        "    line = line.upper()\n",
        "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
        "    for stop_word in stopwords:\n",
        "        line = line.replace(stop_word,' ')\n",
        "        line =  re.sub(r'\\b[0-9(.,)+]*\\b', '', line)\n",
        "    print(line)\n",
        "    return line\n",
        "\n",
        "\n",
        "\n",
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "DEVELOPER_KEY = \"AIzaSyAJft_f_YmksUwI6pi6z_8Hval8tt7pFKo\" #ini Youtube API Key Najla\n",
        "\n",
        "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey = DEVELOPER_KEY)\n",
        "\n",
        "#masukkan channel link\n",
        "channellink = \"UCitm3GpSowvzcd1oYLm5x4g\"\n",
        "\n",
        "# get Uploads playlist id\n",
        "def get_channel_videos(channel_id):\n",
        "    \n",
        "    res = youtube.channels().list(id=channel_id, \n",
        "                                  part='contentDetails').execute()\n",
        "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "    \n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "    \n",
        "    while 1:\n",
        "        res = youtube.playlistItems().list(playlistId=playlist_id, \n",
        "                                           part='snippet', \n",
        "                                           maxResults=50,\n",
        "                                           pageToken=next_page_token).execute()\n",
        "        videos += res['items']\n",
        "        next_page_token = res.get('nextPageToken')\n",
        "        \n",
        "        if next_page_token is None:\n",
        "            break\n",
        "    \n",
        "    return videos\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#mendapatkan link video dari channel yakni video id\n",
        "\n",
        "data=[]\n",
        "videos = get_channel_videos(channellink)\n",
        "\n",
        "\n",
        "for video in videos:\n",
        "    title=video['snippet']['title']\n",
        "    desc=video['snippet']['description']\n",
        "    idv=video['snippet']['resourceId']['videoId']\n",
        "    res = youtube.videos().list(id=idv, part='contentDetails').execute()\n",
        "    duration = res['items'][0]['contentDetails']['duration']\n",
        "    lama=isodate.parse_duration(duration)\n",
        "    hari=parser.parse(video['snippet']['publishedAt']).strftime(\"%w\")\n",
        "    jam=parser.parse(video['snippet']['publishedAt']).strftime(\"%H\")\n",
        "    print(parser.parse(video['snippet']['publishedAt']))\n",
        "    print(hari)\n",
        "    hariku=int(hari)\n",
        "    jami=int(jam)+7\n",
        "    if jami > 23:\n",
        "\t    jami=jami-24\n",
        "\t    hariku=hariku+1\n",
        "    if hariku > 6:\n",
        "\t    hariku=0\n",
        "\n",
        "\n",
        "    if jami < 6 and jami > 21:\n",
        "\t    jami=0\n",
        "    elif jami > 6 and jami < 15:\n",
        "\t    jami=1\n",
        "    else:\n",
        "\t    jami=3 \n",
        "    data.append([hariku,jam,jami,preprocessing(title),lama,preprocessing(desc)])\n",
        "\n",
        "df = pd.DataFrame(data,columns=['hari', 'jam','jami', 'judul','durasi','desc'])\n",
        "print(df)\n",
        "nltk.download('punkt')\n",
        "fdist = FreqDist(sum(df['judul'].map(word_tokenize), []))\n",
        "print(fdist.most_common(10))\n",
        "print(df.groupby('hari').count().max(level=0))\n",
        "print(df.groupby('jam').count().max(level=0))\n",
        "print(df.groupby('hari').agg('count'))\n",
        "print(df.groupby('jami').agg('count'))\n",
        "print(df['durasi'].mean())\n",
        "df.to_csv(\"yb/data_geral.csv\",mode='a', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-92e9f4781c91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0misodate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mSastrawi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStemmerFactory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStemmerFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'isodate'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}